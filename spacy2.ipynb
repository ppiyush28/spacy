{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I am runner running in race beacuase I Live to run Since i ran this morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "beacuase \t NOUN \t 18006690887042883446 \t beacuase\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "Live \t VERB \t 13874798850131827181 \t live\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "Since \t SCONJ \t 10066841407251338481 \t since\n",
      "i \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "this \t DET \t 1995909169258310477 \t this\n",
      "morning \t NOUN \t 128801579471171342 \t morning\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,'\\t', token.pos_, '\\t', token.lemma, '\\t' ,token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  show_lemma(text):\n",
    "    for token in text:\n",
    "        print(f\"{token.text:{12}} {token.pos_:{6}} {token.lemma:{22}} {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON      4690420944186131903 I\n",
      "am           AUX      10382539506755952630 be\n",
      "runner       NOUN     12640964157389618806 runner\n",
      "running      VERB     12767647472892411841 run\n",
      "in           ADP       3002984154512732771 in\n",
      "race         NOUN      8048469955494714898 race\n",
      "beacuase     NOUN     18006690887042883446 beacuase\n",
      "I            PRON      4690420944186131903 I\n",
      "Live         VERB     13874798850131827181 live\n",
      "to           PART      3791531372978436496 to\n",
      "run          VERB     12767647472892411841 run\n",
      "Since        SCONJ    10066841407251338481 since\n",
      "i            PRON      4690420944186131903 I\n",
      "ran          VERB     12767647472892411841 run\n",
      "this         DET       1995909169258310477 this\n",
      "morning      NOUN       128801579471171342 morning\n"
     ]
    }
   ],
   "source": [
    "result = show_lemma(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1= nlp(u\"I saw ten mice this morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON      4690420944186131903 I\n",
      "saw          VERB     11925638236994514241 see\n",
      "ten          NUM       7970704286052693043 ten\n",
      "mice         NOUN      1384165645700560590 mouse\n",
      "this         DET       1995909169258310477 this\n",
      "morning      NOUN       128801579471171342 morning\n"
     ]
    }
   ],
   "source": [
    "result = show_lemma(doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'various', 'any', 'formerly', 'meanwhile', 'throughout', 'made', 'to', 'below', 'whereupon', \"'d\", 'elsewhere', 'yourselves', 'off', 'ten', 'yours', 'onto', 'often', 'was', 'again', 'go', 'twenty', 'perhaps', 'much', 'however', 'several', 'namely', 'this', 'whom', 'sometimes', 'unless', 'while', 'became', 'until', 'can', 'moreover', 'she', '‘s', 'back', 'beyond', 'really', 'besides', 'latter', 'former', 'what', 'out', '’ve', 'seems', 'your', 'around', 'be', 'almost', 'everyone', 'anything', 'all', 'always', 'call', 'my', 'myself', 'once', 'over', 'that', 'although', 'herself', \"'ll\", 'some', 'quite', 'then', 'hereby', 'only', 'or', 'due', 'serious', 'might', 'since', 'hereupon', 'ever', 'see', 'fifteen', 'do', 'by', 'front', 'doing', 'least', 'every', 'twelve', 'next', 'such', 'no', 'thence', 'its', 'did', 'hundred', 'using', 'first', \"'re\", 'he', 'through', 'empty', 'has', 'noone', 'those', 'herein', 'give', 'during', 'along', 'them', 'whereafter', 'within', 'are', 'either', 'mostly', 'say', 'us', 'per', 'ours', 'beforehand', 'must', 'as', '‘re', 'each', 'yourself', 'now', 'does', 'everywhere', 'and', 'somehow', 'wherein', 'itself', 'latterly', 'part', 'behind', 'both', 'me', 'were', 'never', 'becoming', 'seem', 'else', 'am', 'third', 'full', 'everything', 'than', 'whether', 'sometime', 'towards', 'but', 'nevertheless', 'being', 'four', 'more', 'few', 'hers', 'anyhow', 'one', 'thereafter', 'last', 'rather', 'i', 'here', 'many', 'if', 'n’t', 'enough', 'regarding', 'done', 'seemed', 'whereby', 'just', 'none', 'via', 'between', 'less', 'whenever', 'anyway', 'neither', 'five', 'which', 'own', 'wherever', 'anyone', 'further', 'because', 'n‘t', 'amongst', '’re', 'beside', 'upon', 'nobody', 'thereupon', 'whose', 'mine', 'toward', 'afterwards', 'whereas', 'you', 'it', 'from', 'sixty', 'eleven', 'other', 'could', 'ca', 'may', 'therein', '’ll', 'becomes', 'where', 'otherwise', 'two', 'put', 'these', 'is', 'should', \"'s\", '‘m', 'about', 'eight', 'our', 'across', 'make', 'among', 'been', 'hence', 'whatever', 'even', 'keep', 'nor', 'bottom', \"'m\", 'seeming', 'after', 'still', 'her', 'for', 'get', 'thus', 'side', 'fifty', '’d', 'except', 'thereby', 'at', 'into', 'himself', 're', 'ourselves', 'whither', 'have', 'nothing', 'a', 'though', '‘d', 'top', 'move', 'the', \"'ve\", 'who', '‘ve', 'his', 'before', 'someone', 'also', 'of', 'under', 'anywhere', 'something', 'up', '‘ll', 'whoever', 'without', 'yet', 'together', 'too', 'against', 'already', 'very', 'when', 'three', 'him', 'their', 'name', '’m', 'most', 'we', 'nowhere', 'will', 'thru', 'become', 'forty', 'themselves', 'in', 'therefore', 'same', 'well', 'so', 'others', 'another', 'show', 'above', 'whole', 'had', 'how', 'there', 'not', 'down', 'on', 'somewhere', 'why', 'cannot', 'with', 'whence', 'used', 'alone', '’s', 'take', 'nine', 'indeed', 'hereafter', 'they', 'an', \"n't\", 'please', 'amount', 'six', 'would'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['piyu'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'LOWER' : 'solarpower'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER' : 'solar'}, {'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern2 = [{'LOWER' : 'solar'},{'IS_PUNCT' : 'True'}, {'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower',[pattern,pattern1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'the Solar power industry continues to  grow as demand for Solarpower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches =matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8656102463236116519, 1, 3), (8656102463236116519, 11, 12)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 \t SolarPower \t 1 \t 3 \t Solar power\n",
      "8656102463236116519 \t SolarPower \t 11 \t 12 \t Solarpower\n"
     ]
    }
   ],
   "source": [
    "for matches_id,  start,end in found_matches:\n",
    "    string_id = nlp.vocab.strings[matches_id]\n",
    "    span=doc3[start:end]\n",
    "    print(matches_id, '\\t', string_id,'\\t', start,'\\t', end, '\\t',span.text)\n",
    "    #print('\\n')\n",
    "    #print(string_id, start ,end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### phasematcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = \"the economics is good subject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher= PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list= ['enconomics', 'supply-side enconomics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_pattern = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('EcoMatcher', None, *phrase_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db3ff962e9c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfound_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'matcher' is not defined"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
